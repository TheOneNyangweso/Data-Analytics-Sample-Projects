{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation and Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/module_5_auto.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's only use numeric data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n",
    "    ax2 = sns.distplot(BlueFunction, hist=False,\n",
    "                       color=\"b\", label=BlueName, ax=ax1)\n",
    "\n",
    "    plt.title(Title)\n",
    "    plt.xlabel('Price (in dollars)')\n",
    "    plt.ylabel('Proportion of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def PollyPlot(xtrain, xtest, y_train, y_test, lr, poly_transform):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    # training data\n",
    "    # testing data\n",
    "    # lr:  linear regression object\n",
    "    # poly_transform:  polynomial transformation object\n",
    "\n",
    "    xmax = max([xtrain.values.max(), xtest.values.max()])\n",
    "\n",
    "    xmin = min([xtrain.values.min(), xtest.values.min()])\n",
    "\n",
    "    x = np.arange(xmin, xmax, 0.1)\n",
    "\n",
    "    plt.plot(xtrain, y_train, 'ro', label='Training Data')\n",
    "    plt.plot(xtest, y_test, 'go', label='Test Data')\n",
    "    plt.plot(x, lr.predict(poly_transform.fit_transform(\n",
    "        x.reshape(-1, 1))), label='Predicted Function')\n",
    "    plt.ylim([-10000, 60000])\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1: Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df_numeric['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df_numeric.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.10, random_state=1)\n",
    "\n",
    "print(\"number of test samples :\", x_test.shape[0])\n",
    "print(\"number of training samples:\", x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(\n",
    "    x_data, y_data, test_size=0.40, random_state=0)\n",
    "\n",
    "print(\"number of test samples :\", x_test1.shape[0])\n",
    "print(\"number of training samples:\", x_train1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lre = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.fit(x_train[['horsepower']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.score(x_test[['horsepower']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.score(x_train[['horsepower']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.score(x_test1[['horsepower']], y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.score(x_train1[['horsepower']], y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation Score\n",
    "Sometimes you don't have enough data for testing.\\\n",
    "As a result, you may want to perform cross-validaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross = cross_val_score(lre, x_data[['horsepower']], y_data, cv=4)\n",
    "Rcross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use negative squared error as a score by setting the parameter 'scoring' metric to 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1 * cross_val_score(lre,  x_data[['horsepower']],\n",
    "                     y_data, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rc = cross_val_score(lre, x_data[['horsepower']], y_data, cv=2)\n",
    "Rc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the function 'cross_val_predict' to predict the output. The \\\n",
    "function splits up the data into the specified number of folds, with one \\\n",
    "fold for testing and the other folds are used for training. First, import the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = cross_val_predict(lre, x_data[['horsepower']], y_data, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2: Overfitting, Underfitting and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create Multiple Linear Regression objects and train the model using 'horsepower', 'curb-weight', 'engine-size' and 'highway-mpg' as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train[['horsepower', 'curb-weight',\n",
    "       'engine-size', 'highway-mpg']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = lr.predict(x_train[['horsepower', 'curb-weight',\n",
    "                                 'engine-size', 'highway-mpg']])\n",
    "yhat_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = lr.predict(x_test[['horsepower', 'curb-weight',\n",
    "                               'engine-size', 'highway-mpg']])\n",
    "yhat_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform some model evaluation using the training and testing data separately\\\n",
    "But 1st let's do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\n",
    "DistributionPlot(y_train, yhat_train, \"Actual Values (Train)\",\n",
    "                 \"Predicted Values (Train)\", Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the model is good at predicting seen data(train data). Let us now see test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = 'Distribution  Plot of  Predicted Value Using Testing Data vs Testing-Data Data Distribution'\n",
    "DistributionPlot(y_test, yhat_test, \"Actual Values (Test)\",\n",
    "                 \"Predicted Values (Test)\", Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Comparing Figure 1 and Figure 2, it is evident that the distribution of the test data in Figure 1 is much better at fitting the data. \\\n",
    "This difference in Figure 2 is apparent in the range of 5000 to 15,000. This is where the shape of the distribution is extremely different. \\\n",
    "Let's see if polynomial regression also exhibits a drop in the prediction accuracy when analysing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a polynomial of degree 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.45, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = PolynomialFeatures(5)\n",
    "x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = LinearRegression()\n",
    "poly.fit(x_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = poly.predict(x_test_pr)\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted values:\", yhat[0:4])\n",
    "print(\"True values:\", y_test[0:4].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the function \"PollyPlot\" that we defined at the beginning to display the training data, testing data, and the predicted function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PollyPlot(x_train[['horsepower']], x_test[['horsepower']],\n",
    "          y_train, y_test, poly, pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the estimated function appears to track the data but around 200 horsepower, the function begins to diverge from the data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.score(x_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.score(x_test_pr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A -ve R-score is a sign of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how the R^2 changes on the test data for different polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsqu_test = []\n",
    "\n",
    "order = [1, 2, 3, 4]\n",
    "\n",
    "for n in order:\n",
    "    pr = PolynomialFeatures(n)\n",
    "\n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "\n",
    "    lr.fit(x_train_pr, y_train)\n",
    "\n",
    "    Rsqu_test.append(lr.score(x_test_pr, y_test))\n",
    "\n",
    "# Visualizing our results\n",
    "plt.plot(order, Rsqu_test)\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('R^2')\n",
    "plt.title('R^2 Using Test Data')\n",
    "plt.text(3, 0.75, 'Maximum R^2 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(degree, test_data):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_data, y_data, test_size=test_data, random_state=0)\n",
    "    pr = PolynomialFeatures(degree=degree)\n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "    poly = LinearRegression()\n",
    "    poly.fit(x_train_pr, y_train)\n",
    "    PollyPlot(x_train['horsepower'], x_test['horsepower'],\n",
    "              y_train, y_test, poly, pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an interface that allows one to experiment with different polynomial orders and different amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(f, degree=(0, 6, 1), test_data=(0.05, 0.95, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform polynomial transformations with more than one feature. e.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pr1 = pr1.fit_transform(\n",
    "    x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
    "x_test_pr1 = pr1.fit_transform(\n",
    "    x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pr1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wr can see that transforming using the Polynomial basis function results to a matrix with 15 features from 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly1 = lr.fit(x_train_pr1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = 'Distribution  Plot of  Predicted Value Using Testing Data vs Actual Testing-Data Data Distribution'\n",
    "# DistributionPlot(y_test, yhat_test, \"Actual Values (Train)\",\n",
    "#                  \"Predicted Values (Train)\", Title)\n",
    "yhat_test1 = poly1.predict(x_test_pr1)\n",
    "DistributionPlot(y_test, yhat_test1, \"Actual Values (Test)\",\n",
    "                 \"Predicted Values (Test)\", Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted value is higher than actual value for cars where the price $10,000 range, conversely the predicted price is lower than the price cost in the $30,000 to $40,000 range. As such the model is not as accurate in these ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 3 : Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = PolynomialFeatures(degree=2)\n",
    "x_train_pr = pr.fit_transform(\n",
    "    x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg', 'normalized-losses', 'symboling']])\n",
    "x_test_pr = pr.fit_transform(\n",
    "    x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg', 'normalized-losses', 'symboling']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Ridge regression object and set alpha to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeModel = Ridge(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeModel.fit(x_train_pr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = RidgeModel.predict(x_test_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicted:', yhat[0:4])\n",
    "print('test set :', y_test[0:4].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the value of alpha that minimizes the test error. To do so, we can use a for loop. We have also created a progress bar to see how many iterations we have completed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "Rsqu_test = []\n",
    "Rsqu_train = []\n",
    "dummy1 = []\n",
    "Alpha = 10 * np.array(range(0, 1000))\n",
    "pbar = tqdm(Alpha)\n",
    "\n",
    "for alpha in pbar:\n",
    "    RigeModel = Ridge(alpha=alpha)\n",
    "    RigeModel.fit(x_train_pr, y_train)\n",
    "    test_score, train_score = RigeModel.score(\n",
    "        x_test_pr, y_test), RigeModel.score(x_train_pr, y_train)\n",
    "\n",
    "    pbar.set_postfix({\"Test Score\": test_score, \"Train Score\": train_score})\n",
    "\n",
    "    Rsqu_test.append(test_score)\n",
    "    Rsqu_train.append(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visulaize our findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 12\n",
    "height = 10\n",
    "\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.plot(Alpha, Rsqu_test, label='validation data  ')\n",
    "plt.plot(Alpha, Rsqu_train, 'r', label='training Data ')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red line in Figure above represents the R^2 of the training data. As alpha increases the R^2 decreases. Therefore, as alpha increases, the model performs worse on the training data\n",
    "\n",
    "The blue line represents the R^2 on the validation data. As the value for alpha increases, the R^2 increases and converges at a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = Ridge(alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm.fit(x_train_pr, y_train)\n",
    "rm.score(x_test_pr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 4 : Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term alpha is a hyperparameter. Sklearn has the class GridSearchCV to make the process of finding the best hyperparameter simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dict of parameters to be passed to the grid\n",
    "parameters1 = [\n",
    "    {'alpha': [0.001, 0.1, 1, 10, 100, 1000, 10000, 100000, 100000]}]\n",
    "parameters1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = GridSearchCV(RR, parameters1, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1.fit(x_data[['horsepower', 'curb-weight',\n",
    "          'engine-size', 'highway-mpg']], y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRR = grid1.best_estimator_\n",
    "BestRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the best alpha is 10000, let's see how the best model performs to our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRR.score(x_test[['horsepower', 'curb-weight',\n",
    "             'engine-size', 'highway-mpg']], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the r^2 score up to 84%, one can see that using Grid search, we are able to find the best hyperparams more easily."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
